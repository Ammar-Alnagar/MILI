"""
RMSNorm (Root Mean Square Layer Normalization) GPU Kernel Implementation for MILI.
Efficient GPU kernel for applying RMSNorm to activations.

RMSNorm formula:
output = (input / RMS(input)) * weight
where RMS(x) = sqrt(mean(x^2) + epsilon)
"""

from utils.types import (
    DType, TensorMetadata, DeviceContext, KernelConfig,
    GPUConfig, ThreadIdx, BlockIdx
)
import math


# ============================================================================
# RMSNorm Kernel Configuration
# ============================================================================

@register_passable("trivial")
struct RMSNormConfig:
    """Configuration for RMSNorm kernel execution."""
    var epsilon: Float32      # Small value for numerical stability (1e-6)
    var use_fp16: Bool        # Whether to use fp16 computation
    var fused_with_residual: Bool  # Fuse residual connection
    var use_warp_reduce: Bool  # Use warp-level reduction
    var threads_per_block: Int32  # Threads per block
    
    fn __init__(
        epsilon: Float32 = 1e-6,
        use_fp16: Bool = False,
        fused_with_residual: Bool = False,
    ) -> Self:
        return Self(
            epsilon=epsilon,
            use_fp16=use_fp16,
            fused_with_residual=fused_with_residual,
            use_warp_reduce=True,
            threads_per_block=256
        )


# ============================================================================
# RMSNorm Kernel
# ============================================================================

struct RMSNormKernel:
    """GPU kernel for RMSNorm normalization."""
    
    var context: DeviceContext
    var metadata: TensorMetadata
    var config: RMSNormConfig
    
    fn __init__(
        context: DeviceContext,
        metadata: TensorMetadata,
        config: RMSNormConfig,
    ) -> Self:
        return Self(
            context=context,
            metadata=metadata,
            config=config
        )
    
    fn compute_rms_warp_reduce(
        values: DynamicVector[Float32],
        warp_size: Int32 = 32
    ) -> Float32:
        """
        Compute RMS using warp-level reduction.
        More efficient than global reduction for GPU execution.
        """
        var sum_sq: Float32 = 0.0
        
        // First, compute sum of squares locally
        for val in values:
            sum_sq += val * val
        
        // Warp reduction (simulated - in real CUDA would use __shfl_down)
        for offset in range(1, warp_size, offset * 2):
            // In real GPU: sum_sq += __shfl_down(sum_sq, offset)
            if len(values) > offset:
                sum_sq += values[offset]
        
        let mean_sq = sum_sq / Float32(len(values))
        return sqrt(mean_sq + self.config.epsilon)
    
    fn compute_rms_standard(
        values: DynamicVector[Float32]
    ) -> Float32:
        """
        Standard RMS computation without warp-level optimizations.
        Formula: RMS = sqrt(mean(x^2) + epsilon)
        """
        var sum_sq: Float32 = 0.0
        
        for val in values:
            sum_sq += val * val
        
        let mean_sq = sum_sq / Float32(len(values))
        return sqrt(mean_sq + self.config.epsilon)
    
    fn compute_rms(
        self,
        ptr: DTypePointer[DType.float32],
        dim: Int32
    ) -> Float32:
        """
        Compute RMS of a vector.
        
        Args:
            ptr: Pointer to vector data
            dim: Vector dimension
            
        Returns:
            RMS value
        """
        if self.config.use_warp_reduce and dim >= 32:
            // Use warp reduction for vectors >= 32 elements
            var values = DynamicVector[Float32](capacity=min(32, dim))
            for i in range(min(32, dim)):
                values.push_back(ptr[i])
            return self.compute_rms_warp_reduce(values)
        else:
            // Standard reduction for smaller vectors
            var sum_sq: Float32 = 0.0
            for i in range(dim):
                let val = ptr[i]
                sum_sq += val * val
            let mean_sq = sum_sq / Float32(dim)
            return sqrt(mean_sq + self.config.epsilon)
    
    fn compute_rmsnorm_thread(
        inout self,
        thread_idx: Int32,
        block_idx: Int32,
        input_ptr: DTypePointer[DType.float32],
        weight_ptr: DTypePointer[DType.float32],
        output_ptr: DTypePointer[DType.float32],
        residual_ptr: DTypePointer[DType.float32] = DTypePointer[DType.float32]()
    ):
        """
        Compute RMSNorm for elements assigned to this thread.
        
        CUDA-style kernel: threads process different rows in parallel.
        Each thread normalizes one complete vector (all hidden dimensions).
        """
        let batch_size = self.metadata.batch_size
        let seq_length = self.metadata.seq_length
        let hidden_size = self.metadata.hidden_size()
        
        // Each thread handles one sequence position across all batch/sequence
        let total_tokens = batch_size * seq_length
        let token_idx = thread_idx
        
        if token_idx >= total_tokens:
            return  // Out of bounds
        
        let input_offset = token_idx * hidden_size
        
        // Load input vector for this token
        var input_vec = DynamicVector[Float32](capacity=hidden_size)
        for i in range(hidden_size):
            input_vec.push_back(input_ptr[input_offset + i])
        
        // Compute RMS
        let rms = self.compute_rms(input_ptr.offset(input_offset), hidden_size)
        let inv_rms = 1.0 / rms
        
        // Apply normalization and scaling
        for i in range(hidden_size):
            let idx = input_offset + i
            let normalized = input_ptr[idx] * inv_rms
            
            // Apply weight scaling
            let scaled = normalized * weight_ptr[i]
            
            // Optional: fused residual addition
            if self.config.fused_with_residual and residual_ptr:
                output_ptr[idx] = scaled + residual_ptr[idx]
            else:
                output_ptr[idx] = scaled
    
    fn kernel_launch(
        inout self,
        input_ptr: DTypePointer[DType.float32],
        weight_ptr: DTypePointer[DType.float32],
        output_ptr: DTypePointer[DType.float32],
        residual_ptr: DTypePointer[DType.float32] = DTypePointer[DType.float32]()
    ):
        """
        Launch the RMSNorm kernel with CUDA-style grid/block structure.
        
        Grid structure:
        - Each block handles multiple tokens
        - Each thread handles one complete token (all hidden dimensions)
        - Threads work in parallel across sequence length and batch
        """
        let batch_size = self.metadata.batch_size
        let seq_length = self.metadata.seq_length
        let total_tokens = batch_size * seq_length
        
        let block_size = self.config.threads_per_block
        let grid_size = (total_tokens + block_size - 1) // block_size
        
        self.context.config.block_size_x = block_size
        self.context.config.grid_size_x = grid_size
        
        // Execute kernel on each thread
        for block_idx in range(grid_size):
            for thread_idx in range(block_size):
                let global_thread_id = block_idx * block_size + thread_idx
                if global_thread_id < total_tokens:
                    self.compute_rmsnorm_thread(
                        global_thread_id,
                        block_idx,
                        input_ptr,
                        weight_ptr,
                        output_ptr,
                        residual_ptr
                    )
    
    fn forward(
        inout self,
        input_ptr: DTypePointer[DType.float32],
        weight_ptr: DTypePointer[DType.float32],
        output_ptr: DTypePointer[DType.float32],
    ):
        """
        Forward pass: apply RMSNorm normalization.
        
        Formula: output = (input / RMS(input)) * weight
        
        Args:
            input_ptr: Input tensor [batch, seq_len, hidden_size]
            weight_ptr: Learnable weight (scale) [hidden_size]
            output_ptr: Output tensor [batch, seq_len, hidden_size]
        """
        self.kernel_launch(input_ptr, weight_ptr, output_ptr)
    
    fn forward_with_residual(
        inout self,
        input_ptr: DTypePointer[DType.float32],
        weight_ptr: DTypePointer[DType.float32],
        residual_ptr: DTypePointer[DType.float32],
        output_ptr: DTypePointer[DType.float32],
    ):
        """
        Forward pass with fused residual connection.
        
        Formula: output = (input / RMS(input)) * weight + residual
        
        Args:
            input_ptr: Input tensor
            weight_ptr: Learnable weight
            residual_ptr: Residual tensor to add
            output_ptr: Output tensor
        """
        self.kernel_launch(input_ptr, weight_ptr, output_ptr, residual_ptr)


# ============================================================================
# Grouped RMSNorm Variant (for multi-group normalization)
# ============================================================================

struct GroupedRMSNormKernel:
    """
    RMSNorm kernel with group normalization.
    Normalizes within groups instead of across entire hidden dimension.
    """
    
    var base_kernel: RMSNormKernel
    var num_groups: Int32
    var group_size: Int32
    
    fn __init__(
        base_kernel: RMSNormKernel,
        num_groups: Int32
    ) -> Self:
        let hidden_size = base_kernel.metadata.hidden_size()
        let group_size = hidden_size // num_groups
        return Self(
            base_kernel=base_kernel,
            num_groups=num_groups,
            group_size=group_size
        )
    
    fn forward(
        inout self,
        input_ptr: DTypePointer[DType.float32],
        weight_ptr: DTypePointer[DType.float32],
        output_ptr: DTypePointer[DType.float32],
    ):
        """Apply grouped RMSNorm."""
        let batch_size = self.base_kernel.metadata.batch_size
        let seq_length = self.base_kernel.metadata.seq_length
        let hidden_size = self.base_kernel.metadata.hidden_size()
        
        // Process each group independently
        for batch in range(batch_size):
            for seq in range(seq_length):
                for group in range(self.num_groups):
                    let token_offset = (batch * seq_length + seq) * hidden_size
                    let group_start = token_offset + group * self.group_size
                    
                    // Compute RMS for this group
                    var sum_sq: Float32 = 0.0
                    for i in range(self.group_size):
                        let val = input_ptr[group_start + i]
                        sum_sq += val * val
                    
                    let mean_sq = sum_sq / Float32(self.group_size)
                    let rms = sqrt(mean_sq + self.base_kernel.config.epsilon)
                    let inv_rms = 1.0 / rms
                    
                    // Apply normalization and scaling
                    for i in range(self.group_size):
                        let idx = group_start + i
                        let normalized = input_ptr[idx] * inv_rms
                        output_ptr[idx] = normalized * weight_ptr[i]


# ============================================================================
# Utility Functions
# ============================================================================

fn compute_rms_stable(
    ptr: DTypePointer[DType.float32],
    dim: Int32,
    epsilon: Float32 = 1e-6
) -> Float32:
    """
    Compute RMS with numerical stability.
    Uses Welford's online algorithm to avoid overflow/underflow.
    """
    var mean: Float32 = 0.0
    var M2: Float32 = 0.0
    
    for i in range(dim):
        let delta = ptr[i] - mean
        mean += delta / Float32(i + 1)
        let delta2 = ptr[i] - mean
        M2 += delta * delta2
    
    let variance = M2 / Float32(dim)
    return sqrt(variance + epsilon)


fn fused_rmsnorm_residual(
    input_ptr: DTypePointer[DType.float32],
    weight_ptr: DTypePointer[DType.float32],
    residual_ptr: DTypePointer[DType.float32],
    output_ptr: DTypePointer[DType.float32],
    dim: Int32,
    epsilon: Float32 = 1e-6
):
    """
    Fused operation: RMSNorm + residual addition.
    More efficient than separate operations.
    """
    // Compute RMS
    var sum_sq: Float32 = 0.0
    for i in range(dim):
        sum_sq += input_ptr[i] * input_ptr[i]
    
    let mean_sq = sum_sq / Float32(dim)
    let rms = sqrt(mean_sq + epsilon)
    let inv_rms = 1.0 / rms
    
    // Apply normalization, scaling, and residual in one pass
    for i in range(dim):
        let normalized = input_ptr[i] * inv_rms
        let scaled = normalized * weight_ptr[i]
        output_ptr[i] = scaled + residual_ptr[i]


fn layer_norm_to_rmsnorm(
    input_ptr: DTypePointer[DType.float32],
    weight_ptr: DTypePointer[DType.float32],
    bias_ptr: DTypePointer[DType.float32],
    output_ptr: DTypePointer[DType.float32],
    dim: Int32,
    epsilon: Float32 = 1e-6
):
    """
    Convert LayerNorm computation to RMSNorm-compatible format.
    Ignores bias term (RMSNorm doesn't use bias).
    """
    // Compute RMS (ignoring mean centering of LayerNorm)
    var sum_sq: Float32 = 0.0
    for i in range(dim):
        sum_sq += input_ptr[i] * input_ptr[i]
    
    let mean_sq = sum_sq / Float32(dim)
    let rms = sqrt(mean_sq + epsilon)
    let inv_rms = 1.0 / rms
    
    // Apply RMSNorm (weight scaling, no bias)
    for i in range(dim):
        let normalized = input_ptr[i] * inv_rms
        output_ptr[i] = normalized * weight_ptr[i]
