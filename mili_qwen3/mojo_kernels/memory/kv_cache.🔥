"""
Paged KV Cache Kernel Implementation for MILI.
Implements efficient paged memory management for KV cache with reference counting,
block allocation, and RadixAttention support for prefix sharing.

Key Features:
- Fixed-size pages (typically 16 tokens per page)
- Independent block allocation/deallocation
- Reference counting for multi-request sharing
- Efficient gather/scatter operations
"""

from utils.types import (
    DType, TensorMetadata, DeviceContext
)
import math


# ============================================================================
# Paged KV Cache Configuration
# ============================================================================

@register_passable("trivial")
struct PagedKVCacheConfig:
    """Configuration for paged KV cache."""
    var page_size: Int32         # Tokens per page (typically 16)
    var num_pages: Int32         # Total number of pages
    var head_dim: Int32          # Dimension per attention head
    var num_kv_heads: Int32      # Number of KV heads
    var dtype_bytes: Int32       # Bytes per element (4 for float32)
    var enable_prefix_sharing: Bool
    
    fn __init__(
        page_size: Int32 = 16,
        num_pages: Int32 = 1024,
        head_dim: Int32 = 128,
        num_kv_heads: Int32 = 8,
        dtype_bytes: Int32 = 4,
        enable_prefix_sharing: Bool = True
    ) -> Self:
        return Self(
            page_size=page_size,
            num_pages=num_pages,
            head_dim=head_dim,
            num_kv_heads=num_kv_heads,
            dtype_bytes=dtype_bytes,
            enable_prefix_sharing=enable_prefix_sharing
        )
    
    fn page_size_bytes(self) -> Int32:
        """Size of one page in bytes."""
        return self.page_size * self.num_kv_heads * self.head_dim * self.dtype_bytes
    
    fn total_cache_bytes(self) -> Int32:
        """Total cache size for both K and V (2x multiplier)."""
        return 2 * self.num_pages * self.page_size_bytes()


# ============================================================================
# Page Metadata and Status
# ============================================================================

@register_passable("trivial")
struct PageStatus:
    """Status and metadata for a single page."""
    var is_free: Bool           # Whether page is available for allocation
    var ref_count: UInt32       # Number of requests referencing this page
    var owner_request_id: Int32 # ID of owning request (-1 if shared)
    var next_page: Int32        # Linked list pointer to next page (-1 if last)
    var prev_page: Int32        # Linked list pointer to previous page (-1 if first)


struct PagedKVCacheMetadata:
    """Metadata for all pages in cache."""
    var page_statuses: DynamicVector[PageStatus]
    var free_pages: DynamicVector[Int32]  # Stack of free page indices
    var page_offsets: DynamicVector[Int32]  # Byte offset of each page in cache
    var config: PagedKVCacheConfig
    
    fn __init__(config: PagedKVCacheConfig) -> Self:
        var page_statuses = DynamicVector[PageStatus](capacity=config.num_pages)
        var free_pages = DynamicVector[Int32](capacity=config.num_pages)
        var page_offsets = DynamicVector[Int32](capacity=config.num_pages)
        
        // Initialize all pages as free
        for i in range(config.num_pages):
            page_statuses.push_back(PageStatus(
                is_free=True,
                ref_count=0,
                owner_request_id=-1,
                next_page=-1,
                prev_page=-1
            ))
            free_pages.push_back(i)
            
            let offset = i * config.page_size_bytes()
            page_offsets.push_back(offset)
        
        return Self(
            page_statuses=page_statuses,
            free_pages=free_pages,
            page_offsets=page_offsets,
            config=config
        )
    
    fn get_page_offset(self, page_id: Int32) -> Int32:
        """Get byte offset of page in cache buffer."""
        if page_id < 0 or page_id >= len(self.page_offsets):
            return -1
        return self.page_offsets[page_id]
    
    fn is_page_free(self, page_id: Int32) -> Bool:
        """Check if page is available."""
        if page_id < 0 or page_id >= len(self.page_statuses):
            return False
        return self.page_statuses[page_id].is_free
    
    fn get_page_ref_count(self, page_id: Int32) -> UInt32:
        """Get reference count for a page."""
        if page_id < 0 or page_id >= len(self.page_statuses):
            return 0
        return self.page_statuses[page_id].ref_count


# ============================================================================
# Paged KV Cache Allocator
# ============================================================================

struct PagedKVCacheAllocator:
    """Memory allocator for paged KV cache."""
    
    var config: PagedKVCacheConfig
    var metadata: PagedKVCacheMetadata
    var allocation_table: DynamicVector[DynamicVector[Int32]]  # request_id -> page list
    
    fn __init__(config: PagedKVCacheConfig) -> Self:
        let metadata = PagedKVCacheMetadata(config)
        let allocation_table = DynamicVector[DynamicVector[Int32]]()
        
        return Self(
            config=config,
            metadata=metadata,
            allocation_table=allocation_table
        )
    
    fn allocate_pages(
        inout self,
        request_id: Int32,
        num_pages: Int32
    ) -> DynamicVector[Int32]:
        """
        Allocate pages for a request.
        
        Args:
            request_id: ID of requesting process
            num_pages: Number of pages needed
            
        Returns:
            List of allocated page IDs
        """
        var allocated_pages = DynamicVector[Int32](capacity=num_pages)
        
        for i in range(num_pages):
            if len(self.metadata.free_pages) == 0:
                // Out of memory - return what we allocated
                break
            
            let page_id = self.metadata.free_pages.pop_back()
            
            // Update page status
            self.metadata.page_statuses[page_id].is_free = False
            self.metadata.page_statuses[page_id].ref_count = 1
            self.metadata.page_statuses[page_id].owner_request_id = request_id
            
            allocated_pages.push_back(page_id)
        
        // Store in allocation table
        while len(self.allocation_table) <= request_id:
            self.allocation_table.push_back(DynamicVector[Int32]())
        
        // Extend allocation table for this request
        for page_id in allocated_pages:
            self.allocation_table[request_id].push_back(page_id)
        
        return allocated_pages
    
    fn free_pages(
        inout self,
        request_id: Int32,
        page_ids: DynamicVector[Int32]
    ):
        """
        Free pages allocated to a request.
        
        Args:
            request_id: ID of requesting process
            page_ids: List of page IDs to free
        """
        for page_id in page_ids:
            if page_id < 0 or page_id >= self.config.num_pages:
                continue  // Invalid page ID
            
            // Decrement reference count
            self.metadata.page_statuses[page_id].ref_count -= 1
            
            // If no more references, return to free pool
            if self.metadata.page_statuses[page_id].ref_count == 0:
                self.metadata.page_statuses[page_id].is_free = True
                self.metadata.free_pages.push_back(page_id)
    
    fn add_page_reference(
        inout self,
        page_id: Int32
    ):
        """Increment reference count for a page (for sharing)."""
        if page_id >= 0 and page_id < self.config.num_pages:
            self.metadata.page_statuses[page_id].ref_count += 1
    
    fn get_allocated_pages(
        self,
        request_id: Int32
    ) -> DynamicVector[Int32]:
        """Get all pages allocated to a request."""
        if request_id < 0 or request_id >= len(self.allocation_table):
            return DynamicVector[Int32]()
        return self.allocation_table[request_id]


# ============================================================================
# KV Cache Access Operations
# ============================================================================

struct PagedKVCacheAccessor:
    """Accessor for reading/writing paged KV cache."""
    
    var k_cache: DTypePointer[DType.float32]
    var v_cache: DTypePointer[DType.float32]
    var allocator: PagedKVCacheAllocator
    
    fn __init__(
        k_cache: DTypePointer[DType.float32],
        v_cache: DTypePointer[DType.float32],
        allocator: PagedKVCacheAllocator
    ) -> Self:
        return Self(
            k_cache=k_cache,
            v_cache=v_cache,
            allocator=allocator
        )
    
    fn write_kv_to_page(
        inout self,
        page_id: Int32,
        k_data: DTypePointer[DType.float32],
        v_data: DTypePointer[DType.float32],
        num_tokens: Int32
    ):
        """
        Write KV data to a cache page.
        
        Args:
            page_id: Target page ID
            k_data: Key data to write
            v_data: Value data to write
            num_tokens: Number of tokens to write (max page_size)
        """
        let offset = self.allocator.metadata.get_page_offset(page_id)
        if offset < 0:
            return  // Invalid page
        
        let write_size = min(num_tokens, self.allocator.config.page_size)
        let kv_size = write_size * self.allocator.config.num_kv_heads * self.allocator.config.head_dim
        
        // Copy K data
        for i in range(kv_size):
            self.k_cache[offset + i] = k_data[i]
        
        // Copy V data
        for i in range(kv_size):
            self.v_cache[offset + i] = v_data[i]
    
    fn read_kv_from_page(
        self,
        page_id: Int32,
        k_output: DTypePointer[DType.float32],
        v_output: DTypePointer[DType.float32],
        num_tokens: Int32
    ):
        """
        Read KV data from a cache page.
        
        Args:
            page_id: Source page ID
            k_output: Output buffer for keys
            v_output: Output buffer for values
            num_tokens: Number of tokens to read
        """
        let offset = self.allocator.metadata.get_page_offset(page_id)
        if offset < 0:
            return  // Invalid page
        
        let read_size = min(num_tokens, self.allocator.config.page_size)
        let kv_size = read_size * self.allocator.config.num_kv_heads * self.allocator.config.head_dim
        
        // Copy K data
        for i in range(kv_size):
            k_output[i] = self.k_cache[offset + i]
        
        // Copy V data
        for i in range(kv_size):
            v_output[i] = self.v_cache[offset + i]
    
    fn gather_pages(
        self,
        page_ids: DynamicVector[Int32],
        output_k: DTypePointer[DType.float32],
        output_v: DTypePointer[DType.float32],
        total_tokens: Int32
    ):
        """
        Gather KV data from multiple pages into contiguous buffer.
        Useful for computing attention over cached tokens.
        
        Args:
            page_ids: List of pages to gather from
            output_k: Output buffer for concatenated keys
            output_v: Output buffer for concatenated values
            total_tokens: Total tokens to gather
        """
        let kv_size = self.allocator.config.num_kv_heads * self.allocator.config.head_dim
        var write_offset = 0
        
        for page_id in page_ids:
            let page_offset = self.allocator.metadata.get_page_offset(page_id)
            if page_offset < 0:
                continue
            
            let tokens_in_page = min(
                self.allocator.config.page_size,
                total_tokens - write_offset
            )
            let copy_size = tokens_in_page * kv_size
            
            // Copy K data from page
            for i in range(copy_size):
                output_k[write_offset * kv_size + i] = self.k_cache[page_offset + i]
            
            // Copy V data from page
            for i in range(copy_size):
                output_v[write_offset * kv_size + i] = self.v_cache[page_offset + i]
            
            write_offset += tokens_in_page
            
            if write_offset >= total_tokens:
                break
    
    fn scatter_pages(
        inout self,
        page_ids: DynamicVector[Int32],
        input_k: DTypePointer[DType.float32],
        input_v: DTypePointer[DType.float32],
        total_tokens: Int32
    ):
        """
        Scatter KV data from contiguous buffer to multiple pages.
        Inverse operation of gather_pages.
        
        Args:
            page_ids: List of pages to scatter to
            input_k: Input buffer with keys
            input_v: Input buffer with values
            total_tokens: Total tokens to scatter
        """
        let kv_size = self.allocator.config.num_kv_heads * self.allocator.config.head_dim
        var read_offset = 0
        
        for page_id in page_ids:
            let page_offset = self.allocator.metadata.get_page_offset(page_id)
            if page_offset < 0:
                continue
            
            let tokens_in_page = min(
                self.allocator.config.page_size,
                total_tokens - read_offset
            )
            let copy_size = tokens_in_page * kv_size
            
            // Copy K data to page
            for i in range(copy_size):
                self.k_cache[page_offset + i] = input_k[read_offset * kv_size + i]
            
            // Copy V data to page
            for i in range(copy_size):
                self.v_cache[page_offset + i] = input_v[read_offset * kv_size + i]
            
            read_offset += tokens_in_page
            
            if read_offset >= total_tokens:
                break


# ============================================================================
# Radix Tree for Prefix Sharing
# ============================================================================

@register_passable("trivial")
struct RadixNodeId:
    """Identifier for a radix tree node."""
    var node_id: Int32


struct RadixNode:
    """Node in radix tree for prefix sharing."""
    var key: DynamicVector[Int32]  # Prefix tokens
    var pages: DynamicVector[Int32]  # Cached pages for this prefix
    var ref_count: UInt32          # Reference count
    var children: DynamicVector[Int32]  # Child node IDs
    var parent_id: Int32           # Parent node ID (-1 if root)
    
    fn __init__() -> Self:
        return Self(
            key=DynamicVector[Int32](),
            pages=DynamicVector[Int32](),
            ref_count=0,
            children=DynamicVector[Int32](),
            parent_id=-1
        )


struct RadixAttentionCache:
    """
    Radix tree-based KV cache with prefix sharing.
    Allows multiple requests to share common prefix caches.
    """
    
    var nodes: DynamicVector[RadixNode]
    var allocator: PagedKVCacheAllocator
    var root_id: Int32
    
    fn __init__(allocator: PagedKVCacheAllocator) -> Self:
        var nodes = DynamicVector[RadixNode]()
        
        // Create root node
        var root = RadixNode()
        root.parent_id = -1
        nodes.push_back(root)
        
        return Self(
            nodes=nodes,
            allocator=allocator,
            root_id=0
        )
    
    fn find_common_prefix_length(
        self,
        tokens1: DynamicVector[Int32],
        tokens2: DynamicVector[Int32]
    ) -> Int32:
        """Find length of common prefix between two token sequences."""
        let min_len = min(len(tokens1), len(tokens2))
        var common_len = 0
        
        for i in range(min_len):
            if tokens1[i] == tokens2[i]:
                common_len += 1
            else:
                break
        
        return common_len
    
    fn add_request(
        inout self,
        request_id: Int32,
        prompt_tokens: DynamicVector[Int32]
    ) -> DynamicVector[Int32]:
        """
        Add a new request to the cache, potentially sharing prefix with existing requests.
        
        Returns:
            List of cache pages allocated for this request
        """
        var allocated_pages = DynamicVector[Int32]()
        
        // Find best existing node to branch from
        var best_match_node_id = self.root_id
        var best_match_length = 0
        
        for node_id in range(len(self.nodes)):
            let common_len = self.find_common_prefix_length(
                self.nodes[node_id].key,
                prompt_tokens
            )
            
            if common_len > best_match_length:
                best_match_node_id = node_id
                best_match_length = common_len
        
        // Add reference to shared prefix
        if best_match_length > 0:
            self.allocator.add_page_reference(best_match_node_id)
            
            for page_id in self.nodes[best_match_node_id].pages:
                allocated_pages.push_back(page_id)
        
        // Allocate pages for unique suffix
        let unique_tokens = len(prompt_tokens) - best_match_length
        let pages_needed = (unique_tokens + self.allocator.config.page_size - 1) // self.allocator.config.page_size
        
        let new_pages = self.allocator.allocate_pages(request_id, pages_needed)
        
        for page_id in new_pages:
            allocated_pages.push_back(page_id)
        
        return allocated_pages
    
    fn release_request(
        inout self,
        request_id: Int32,
        page_ids: DynamicVector[Int32]
    ):
        """Release pages allocated to a request."""
        self.allocator.free_pages(request_id, page_ids)


# ============================================================================
# Utility Functions
# ============================================================================

fn compute_pages_needed(
    seq_len: Int32,
    page_size: Int32
) -> Int32:
    """Calculate number of pages needed for a sequence."""
    return (seq_len + page_size - 1) // page_size


fn compute_page_offset_in_bytes(
    page_id: Int32,
    page_size_bytes: Int32
) -> Int32:
    """Compute byte offset of a page."""
    return page_id * page_size_bytes


fn compute_token_offset_in_page(
    token_idx: Int32,
    page_size: Int32,
    num_kv_heads: Int32,
    head_dim: Int32
) -> Int32:
    """Compute offset of a token within its page."""
    let idx_in_page = token_idx % page_size
    return idx_in_page * num_kv_heads * head_dim * 4  // 4 bytes per float32
